# Integrations and Plugins 

This page documents some of the plugins and integrations that have been added to the SDP, alongside some discussion of their pros and cons.

## GitHub
There are many possibilities with the GitHub integration. One notable feature is its ability to automatically import user, group, and repository information into the catalog. This eliminates the need to manually locate catalog-info.yaml files for all components, ensuring immediate visibility of any new entities in the portal.

### Authentication and permissions 
Currently, GitHub handles the authentication for the SDP. This allows for ownership information to be readily available, as well as handling permissions for access to repositories.

The sign-in system in Backstage is not intended to limit access, only to inform the system of the identity of the user (and provide access tokens for certain integrations). Access limitation is handled by the permission framework as mentioned below.

By default, Backstage endpoints are not protected, and all actions are available to anyone. However, the permission framework allows integrators to achieve this through the use of granular permissioning for those resources and actions.

The SDP uses backstage's permission framework to authnticate access to specific parts of the portal, such as the tech radar or the whole application access dependand on the role based authentication attached to specific groups within the GitHub Org.

Current roles are as follows:

- Admin 
    - Full application access 
    - Entity creation 
    - Entity deletion

- Dev-Team
    - Full application access 
    - Entity creation

- spp-sml 
    - Tech radar access

These roles can be changed or renamed dependant on the configuration of the SDP.

for more information go to [Authentication and permissions](authentication_and_permissions.md)


## Jira

The Jira integration works by specifying a proxy in app-config.yaml in the Backstage project root. This requires a "target", which is the domain that is hosting Jira - for testing purposes, I've set up a dummy organisation at https://akira.atlassian.net/ but this would obviously be replaced by https://jira.ons.gov.uk/ in production. The application also requires an authorisation header using a token generated by the organisation; 

Obtain you personal token from Jira.

Create a base64-encoded string by converting a string in format

`<your-atlassian-account-mail>:<your-jira-token>`

for example:

`jira-mail@example.com:hTBgqVcrcxRYpT5TCzTA9C0F`

converts to base64

`amlyYS1tYWlsQGV4YW1wbGUuY29tOmhUQmdxVmNyY3hSWXBUNVRDelRBOUMwRg==`

Save it as the environmental variable JIRA_TOKEN with Basic prefix, for example:

`JIRA_TOKEN='Basic amlyYS1tYWlsQGV4YW1wbGUuY29tOmhUQmdxVmNyY3hSWXBUNVRDelRBOUMwRg=='`

Alternatively, if you are running backstage locally, you can provide the variable by the command

`env JIRA_TOKEN='Basic amlyYS1tYWlsQGV4YW1wbGUuY29tOmhUQmdxVmNyY3hSWXBUNVRDelRBOUMwRg==' yarn`

Once set up, applying the integration to software components in the catalog is as simple as marking the catalog info file with a jira/project-key annotation. This annotation should map to the key that relates to the project that the component is part of - for example, all of the SML repos would be marked with SPP .

## GitHub Insights

GitHub Insights plugin provides repository insights about contributors, languages, readme, and enviroments - this is the same information that you can see found directly on GitHub but it allows the user to view insights wigets for corresponding componetnts in the catalog  

## AWS

There are two main providers of AWS-Backstage plugins: AWS Apps and Roadie. These are based on the AWS SDK, which is both straightforward to install and easy to make use of. This means that a lot of the AWS functionality can reasonably be done from scratch - for a lot of our use-cases, I think this approach is best.

The existing plugins are discussed below for completeness.

### AWSLabs
AWS themselves provide three such plugins: aws-apps-backend, aws-apps and scaffolder-backend-module-aws-apps ([which are available here](https://github.com/awslabs/app-development-for-backstage-io-on-aws)). Most notably, these allow (among other things):

- Discovery of AWS resources as Backstage entities (such that they're visible in the Software Catalog, with a custom frontend for their pages)
- UI cards to monitor AWS resources from within Backstage
- Scaffolder actions to provision AWS resources using templates

However, the project containing these plugins seems intended to be used as a standalone AWS management platform as opposed to integrated into an existing Backstage app.


### RoadieHQ

The alternative is the Roadie-developed set of Backstage AWS plugins which appears to be more tailored towards being incorporated into an existing Backstage app. However, these have significant limitations:

The range of resources that it can track is very limited - it only recognises S3 buckets, ECRs and Lambda actions.

The frontend for these resources does not seem particularly mature. Aside from only providing a limited number of components, it's not present on yarn or npm, which means that you have to manually install it from source.

These are useful actions, but they're very limited in scope.

## ChatGPT and AI queries

The plugin developed by Enfuse offers a simple user interface for interacting with ChatGPT through OpenAI's chat completion API. Although limited on its own, functioning essentially as a basic version of the OpenAI user interface, the framework provided allowed for the creation of a chat window that enables users to query ChatGPT using information stored within Backstage's database. This provides a natural language interface for exploring Backstage.

To achieve this, context retrieved from Backstage's entity catalogue database (specifically, the YAML files describing entity metadata) was injected into the system prompt, along with a directive for ChatGPT to use that context in its responses. Consequently, when users ask questions, ChatGPT can utilize the metadata to generate informed answers about Backstage's knowledge.

### Token Limitations

However, the model used, ChatGPT-3.5-Turbo, has a combined token limit of 4096 tokens for both system and user prompts. This limit is insufficient to send the entire database content, even when restricted to catalog-info.yaml metadata files, necessitating a method to select the data sent to ChatGPT.

OpenAI's "embeddings" API, which vectorizes text, provides a solution. By vectorizing the database items and the user query, and then comparing them using cosine similarity, a ranking from "most relevant" to "least relevant" is produced. The top N most relevant database items can then be selected as context.

Despite often yielding good results, this approach has fundamental flaws. Since ChatGPT cannot access the entire database at once, it cannot accurately answer large aggregate queries (such as "how many entities are tracked in the database" or "list all entities not using Python") unless all relevant information is contained within the metadata of a small number of entities. There is no real workaround for this issue, but it might not be problematic in a production environment. For instance, the Office for National Statistics (ONS) would likely avoid sending potentially sensitive data to OpenAI, opting instead to host their own language model locally. This would eliminate the token limit issue, though other challenges such as performance and relevance with extremely large contexts might arise.





