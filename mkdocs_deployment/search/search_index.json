{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Software Developer Portal","text":""},{"location":"#overview","title":"Overview","text":"<p>The Software Developer Portal uses Backstage, it is an open source framework for building developer portals. Powered by a centralized software catalog, Backstage restores order to your microservices and infrastructure and enables your product teams to ship high-quality code quickly \u2014 without compromising autonomy.</p> <p>Backstage unifies all your infrastructure tooling, services, and documentation to create a streamlined development environment from end to end.</p>"},{"location":"#backstage-includes","title":"Backstage includes","text":"<p>Backstage Software Catalog for managing all your software: </p> <ul> <li>microservices </li> <li>libraries  </li> <li>data pipelines </li> <li>websites </li> <li>ML models, etc.</li> </ul> <p>Backstage Software Templates for quickly spinning up new projects and standardizing your tooling with your organization\u2019s best practices</p> <p>Backstage TechDocs for making it easy to create, maintain, find, and use technical documentation, using a \"docs like code\" approach</p> <p>Plus, a growing ecosystem of open source plugins that further expand Backstage\u2019s customizability and functionality</p>"},{"location":"#benefits","title":"Benefits","text":"<p>For engineering managers, it allows you to maintain standards and best practices across the organization, and can help you manage your whole tech ecosystem, from migrations to test certification.</p> <p>For end users (developers), it makes it fast and simple to build software components in a standardized way, and it provides a central place to manage all projects and documentation.</p> <p>For platform engineers, it enables extensibility and scalability by letting you easily integrate new tools and services (via plugins), as well as extending the functionality of existing ones.</p> <p>For everyone, it\u2019s a single, consistent experience that ties all your infrastructure tooling, resources, standards, owners, contributors, and administrators together in one place.</p> <p>For full backstage documentation visit backstage.</p>"},{"location":"authentication_and_permissions/","title":"Authentication and Permissions","text":"<p>This page documents steps to setup and integrate organisation authentications and permissions.</p>"},{"location":"authentication_and_permissions/#authentication","title":"Authentication","text":""},{"location":"authentication_and_permissions/#github-apps","title":"GitHub Apps","text":"<p>Backstage can be configured to use GitHub Apps for backend authentication. This comes with advantages such as higher rate limits and that Backstage can act as an application instead of a user or bot account.</p> <p>It also provides a much clearer and better authorisation model as a opposed to the OAuth apps and their respective scopes.</p>"},{"location":"authentication_and_permissions/#caveats","title":"Caveats","text":"<ul> <li> <p>This authentication method is designed for authenticating towards organization repositories, not personal repositories.</p> </li> <li> <p>It is not possible to have multiple Backstage GitHub Apps installed in the same GitHub organization to be managed by Backstage. Currently, the SDP does not check through all the registered GitHub Apps to determine which ones are installed for a particular repository. Only global organization installs are respected at this time.</p> </li> <li> <p>The created GitHub App is private by default, which is generally preferred for github.com.</p> </li> </ul>"},{"location":"authentication_and_permissions/#setup","title":"Setup","text":"<p>A GitHub App created with the CLI will have read access by default. Additional permissions must be manually updated in the GitHub App settings on GitHub if needed.</p> <p>To integrate a GitHub App you can create it using these instructions. Which will automatically link it to your backstage instance.</p> <p>Once the application is created it will generate a YAML file with a <code>privateKey</code> as shown below, the YAML file will be named after your GitHub app e.g <code>backstage-app-credentials.yaml</code>.</p> <pre><code>appId: app id\nclientId: client id\nclientSecret: client secret\nwebhookSecret: webhook secret\nprivateKey: |\n  -----BEGIN RSA PRIVATE KEY-----\n  ...Key content...\n  -----END RSA PRIVATE KEY-----\n</code></pre>"},{"location":"authentication_and_permissions/#permissions","title":"Permissions","text":""},{"location":"authentication_and_permissions/#repository-permissions","title":"Repository permissions","text":""},{"location":"authentication_and_permissions/#organisation-permissions","title":"Organisation permissions","text":""},{"location":"authentication_and_permissions/#including-in-integrations-config","title":"Including in Integrations Config\u200b","text":"<p>Once the credentials are stored in a YAML file generated by create-github-app, they can be included in the app-config.yaml under the integrations section.</p> <p>Please note that the credentials file is highly sensitive and should NOT be checked into any kind of version control. Instead use your preferred secure method of distributing secrets.</p> <pre><code>integrations:\n  github:\n    - host: github.com\n      apps:\n        - $include: example-backstage-app-credentials.yaml\n</code></pre>"},{"location":"authentication_and_permissions/#local-configuration","title":"Local configuration","text":"<p>During local development, the SDP team has been utilising the 'backstage-dummy-org' GitHub Organization. This setup has provided a non-restricted, sandbox environment that allows for testing of functionality, template features, and GitHub integrations.</p> <p>To switch to a different configuration, modifications to app-config.yaml and catalog.ts files will be necessary, particularly in the following areas:</p> <pre><code>#app-config.yaml\ncatalog:\n  providers:\n    github:\n      providerId:\n        organization: '${BSTAGE_GITHUB_ORGANISATION}' - # make sure that the env variable is changed to org you want to use \n</code></pre> <p><pre><code>#app-config.yaml\nintegrations:\n  github:\n    - host: github.com\n      apps:\n        - $include: 'example-backstage-app-credentials.yaml' - # make sure that the correct file is referenced here which is linked to the organisation you want to use\n</code></pre> <pre><code>//catalog.ts \n const githubOrgEntityProvider = GithubOrgEntityProvider.fromConfig(env.config, {\n    id: 'production',\n    orgUrl: 'https://github.com/backstage-dummy-org', - // make the changes here as well to match the organisation you will be using.\n    ...\n</code></pre></p>"},{"location":"authentication_and_permissions/#permissions_1","title":"Permissions","text":"<p>The permissions framework depends on a few other Backstage systems, which must be set up before we can dive into writing a policy.</p>"},{"location":"authentication_and_permissions/#upgrade-to-the-latest-version-of-backstage","title":"Upgrade to the latest version of Backstage\u200b","text":"<p>The permissions framework itself is new to Backstage and still evolving quickly. To ensure your version of Backstage has all the latest permission-related functionality, it\u2019s important to upgrade to the latest version. The Backstage upgrade helper is a great tool to help ensure that you\u2019ve made all the necessary changes during the upgrade!</p>"},{"location":"authentication_and_permissions/#enable-service-to-service-authentication","title":"Enable service-to-service authentication\u200b","text":"<p>Service-to-service authentication allows Backstage backend code to verify that a given request originates from elsewhere in the Backstage backend. This is useful for tasks like collation of catalog entities in the search index. This type of request shouldn\u2019t be permissioned, so it\u2019s important to configure this feature before trying to use the permissions framework.</p> <p>To set up service-to-service authentication, follow the service-to-service authentication docs.</p>"},{"location":"authentication_and_permissions/#integrating-permission-framework-with-your-backstage-instance","title":"Integrating permission framework with your Backstage instance\u200b","text":""},{"location":"authentication_and_permissions/#1-set-up-the-permission-backend","title":"1. Set up the permission backend\u200b","text":"<p>The permissions framework uses a permission-backend plugin to accept authorization requests from other plugins across your Backstage instance. The Backstage backend does not include this permission backend by default, so you will need to add it:</p> <ol> <li> <p>Add @backstage/plugin-permission-backend as a dependency of your Backstage backend:</p> <pre><code># From your Backstage root directory\nyarn add --cwd packages/backend @backstage/plugin-permission-backend\n</code></pre> </li> <li> <p>Add the following to a new file, packages/backend/src/plugins/permission.ts. This adds the permission-backend router, and configures it with a very basic policy which restricts catalog entity read permission.</p> </li> </ol> <pre><code>import {\n  BackstageIdentityResponse,\n  IdentityClient\n} from '@backstage/plugin-auth-node';\nimport { createRouter } from '@backstage/plugin-permission-backend';\nimport {\n  AuthorizeResult,\n  PolicyDecision,\n  isPermission,\n} from '@backstage/plugin-permission-common';\nimport {\n  PermissionPolicy,\n  PolicyQuery,\n} from '@backstage/plugin-permission-node';import { Router } from 'express';\nimport { PluginEnvironment } from '../types';\nimport {\n  catalogConditions,\n  createCatalogConditionalDecision,\n} from '@backstage/plugin-catalog-backend/alpha';\nimport {\n  catalogEntityReadPermission,\n} from '@backstage/plugin-catalog-common/alpha';\n\nclass TestPermissionPolicy implements PermissionPolicy {\n  async handle(\n    request: PolicyQuery,\n    user?: BackstageIdentityResponse,\n  ): Promise&lt;PolicyDecision&gt; {\n    if (isPermission(request.permission, catalogEntityReadPermission)) {\n      return createCatalogConditionalDecision(\n        request.permission,\n        catalogConditions.isEntityOwner({\n          claims: user?.identity.ownershipEntityRefs ?? [],\n        }),\n      );\n    }\n\n    return { result: AuthorizeResult.ALLOW };\n  }\n}\n\nexport default async function createPlugin(\n  env: PluginEnvironment,\n): Promise&lt;Router&gt; {\n  return await createRouter({\n    config: env.config,\n    logger: env.logger,\n    discovery: env.discovery,\n    policy: new TestPermissionPolicy(),\n    identity: env.identity,\n  });\n}\n</code></pre> <ol> <li>Wire up the permission policy in packages/backend/src/index.ts. The index in the example backend shows how to do this. You\u2019ll need to import the module from the previous step, create a plugin environment, and add the router to the express app: <pre><code>import permission from './plugins/permission';\n\n\nconst permissionEnv = useHotMemoize(module, () =&gt; createEnv('permission'));\n\n\napiRouter.use('/permission', await permission(permissionEnv));\n</code></pre></li> </ol>"},{"location":"authentication_and_permissions/#2-enable-and-test-the-permissions-system","title":"2. Enable and test the permissions system\u200b","text":"<p>Now that the permission backend is running, it\u2019s time to enable the permissions framework and make sure it\u2019s working properly.</p> <ol> <li>Set the property permission.enabled to true in app-config.yaml. </li> </ol> <pre><code>permission:\n  enabled: true\n</code></pre>"},{"location":"authentication_and_permissions/#3-custom-permissions","title":"3. Custom permissions","text":"<p>You can also customize the permissions and create your own custom permissions dependant on the application's requirements.</p> <p>Here's a set of custom permissions with basic read functionality which is currently being used by the SDP to restrict access to the whole application and only grant access to the tech radar dependant on which github org group you are part of. </p> <pre><code>#customPermissions.ts\n\nimport { ResourcePermission, createPermission } from \"@backstage/plugin-permission-common\";\n//Permission Definitions\n/**\n * Represents a resource permission for accessing the tech radar catalog entity.\n */\nexport const fullAccess: ResourcePermission&lt;\"catalog-entity\"&gt; = createPermission({\n  /**\n   * The name of the permission.\n   */\n  name: \"catalog.entity.fullAccess\",\n  /**\n   * The attributes of the permission.\n   */\n  attributes: {\n    /**\n     * The action allowed by the permission.\n     */\n    action: \"read\",\n  },\n  /**\n   * The type of the resource associated with the permission.\n   */\n  resourceType: \"catalog-entity\",\n});\n\nexport const techRadarAccess: ResourcePermission&lt;\"catalog-entity\"&gt; = createPermission({\n  name: \"catalog.entity.techRadarAccess\",\n  attributes: {\n    action: \"read\",\n  },\n  resourceType: \"catalog-entity\",\n});\n\nexport const customPermissions = [\n    fullAccess,\n    techRadarAccess\n];\n</code></pre> <p>Here is how the fullAccess permissions is later used in the permission.ts</p> <pre><code>  // Full Access\n  if (isPermission(request.permission, fullAccess)) {\n    if (isPartOfGroup(['admin', 'dev-team'])) {\n      console.log('Allowed full access');\n      return { result: AuthorizeResult.ALLOW };\n    } else {\n      console.log('Denied full access');\n      return { result: AuthorizeResult.DENY };\n    }\n  }\n</code></pre> <p>The permissions are also being declared in packages/app/src/App.tsx to check which permissions are being authenticated thus granting access to specific part of the application.</p> <p>like so:  <pre><code>function CheckPermission(_props:any) {\n\n  const { loading: loadingPermission, allowed: readAllowed } = usePermission({permission: fullAccess, resourceRef: 'packages/backend/src/plugins/permission.ts',});\n\n  let displayContent = &lt;&gt;&lt;AppRouter&gt;&lt;Root&gt;{routes}&lt;/Root&gt;&lt;/AppRouter&gt;&lt;/&gt;;\n\n\n  if (!loadingPermission &amp;&amp; !readAllowed) {\n       displayContent = &lt;&gt;\n       &lt;AppRouter&gt;&lt;Root&gt;&lt;WarningPanel severity= 'info' title= \"Limited Access\" message= 'You are not authorised to have full access to the platform. For further questions and queries about the software developer portal access contact: ............'/&gt;{tech_radar}&lt;/Root&gt;&lt;/AppRouter&gt;&lt;/&gt;;\n\n  }\n  return displayContent;\n}\n</code></pre></p> <p>And in packages/app/src/components/Root/Root.tsx to restrict the navigation routes and buttons dependant on your application access permissions</p> <p>like so: <pre><code>export const Root = ({ children }: PropsWithChildren&lt;{}&gt;) =&gt; {\n  const { allowed: readAllowed } = usePermission({\n    permission: fullAccess,\n    resourceRef: 'packages/backend/src/plugins/permission.ts',\n  });\n\n  const { allowed: readAllowed2 } = usePermission({\n    permission: techRadarAccess, \n    resourceRef: 'packages/backend/src/plugins/permission.ts',\n  });\n\n  const globalRoutes = [\n    &lt;SidebarItem key=\"home\" icon={HomeIcon} to=\"/\" text=\"Home\" /&gt;,\n    &lt;SidebarItem key=\"catalog\" icon={CatalogIcon} to=\"catalog\" text=\"Catalog\" /&gt;,\n    &lt;SidebarItem key=\"api-docs\" icon={ExtensionIcon} to=\"api-docs\" text=\"APIs\" /&gt;,\n    &lt;SidebarItem key=\"docs\" icon={LibraryBooks} to=\"docs\" text=\"Docs\" /&gt;,\n    &lt;SidebarItem key=\"create\" icon={CreateComponentIcon} to=\"create\" text=\"Create...\" /&gt;,\n    &lt;SidebarItem key=\"announcements\" icon={AnnouncmentIcon} to=\"announcements\" text=\"Announcements\" /&gt;,\n    &lt;SidebarItem key=\"onboarding\" icon={OnboardingIcon} to=\"onboarding\" text=\"Onboarding\" /&gt;,\n  ];\n\n  const techRoutes = [\n    &lt;SidebarItem key=\"tech-radar\" icon={MapIcon} to=\"tech-radar\" text=\"Tech Radar\" /&gt;,\n    // Add more tech-related routes here\n  ];\n\n  let sidebarContent;\n\n  if (readAllowed) {\n    sidebarContent = (\n      &lt;SidebarPage&gt;\n        &lt;Sidebar&gt;\n          &lt;SidebarLogo /&gt;\n          &lt;SidebarGroup label=\"Search\" icon={&lt;SearchIcon /&gt;} to=\"/search\"&gt;\n            &lt;SidebarSearchModal /&gt;\n          &lt;/SidebarGroup&gt;\n          &lt;SidebarDivider /&gt;\n          &lt;SidebarGroup label=\"Menu\" icon={&lt;MenuIcon /&gt;}&gt;\n            {globalRoutes}\n          &lt;SidebarDivider /&gt;\n            &lt;SidebarScrollWrapper&gt;{techRoutes}&lt;/SidebarScrollWrapper&gt;\n          &lt;/SidebarGroup&gt;\n          &lt;SidebarSpace /&gt;\n          &lt;SidebarDivider /&gt;\n          &lt;SidebarGroup\n            label=\"Settings\"\n            icon={&lt;UserSettingsSignInAvatar /&gt;}\n            to=\"/settings\"\n          &gt;\n            &lt;SidebarSettings /&gt;\n          &lt;/SidebarGroup&gt;\n        &lt;/Sidebar&gt;\n        {children}\n      &lt;/SidebarPage&gt;\n    ) \n  } else if (readAllowed2) {\n    sidebarContent = (\n      &lt;SidebarPage&gt;\n        &lt;Sidebar&gt;\n          &lt;SidebarLogo /&gt;\n          &lt;SidebarDivider /&gt;\n          &lt;SidebarGroup label=\"Menu\" icon={&lt;MenuIcon /&gt;}&gt;\n            &lt;SidebarDivider /&gt;\n            &lt;SidebarItem key=\"home\" icon={HomeIcon} to=\"/\" text=\"Home\" /&gt;\n            &lt;SidebarScrollWrapper&gt;{techRoutes}&lt;/SidebarScrollWrapper&gt;\n          &lt;/SidebarGroup&gt;\n          &lt;SidebarSpace /&gt;\n          &lt;SidebarDivider /&gt;\n          &lt;SidebarGroup\n            label=\"Settings\"\n            icon={&lt;UserSettingsSignInAvatar /&gt;}\n            to=\"/settings\"\n          &gt;\n            &lt;SidebarSettings /&gt;\n          &lt;/SidebarGroup&gt;\n        &lt;/Sidebar&gt;\n        {children}\n      &lt;/SidebarPage&gt;\n    ) \n  } else {\n    sidebarContent = (\n      &lt;WarningPanel severity='warning' title=\"Unauthorised Access\" message='You are not authorised to have access to the this platform. For further questions and queries about the software developer portal access contact: ............' /&gt;\n    );\n  }\n\n  return sidebarContent;\n}\n</code></pre></p>"},{"location":"aws-deployment/","title":"AWS deployment","text":"<p>This part of the documentation will cover how the SDP is currently deployed in AWS and the future developments. </p>"},{"location":"aws-deployment/#current-sdp-cloud-configuration","title":"Current SDP cloud configuration","text":""},{"location":"aws-deployment/#architecture-diagram","title":"Architecture Diagram","text":"<p>The following shows the current architecture for the SDP.</p> <p></p>"},{"location":"aws-deployment/#architecture-overview","title":"Architecture Overview","text":"<p>The current deployment of the SDP (Service Delivery Platform) is conducted manually without any automation, as it remains in its Proof of Concept (PoC) phase.</p>"},{"location":"aws-deployment/#manual-cloning-and-deployment","title":"Manual Cloning and Deployment","text":"<p>The SDP is manually cloned into the EC2 instance (UK-Backstage-SDP) from the ONSDigital repository ONSDigital/sdp-backstage. This process involves accessing the EC2 instance and executing Git commands to pull the latest codebase.</p>"},{"location":"aws-deployment/#accessing-the-ec2-instance","title":"Accessing the EC2 Instance","text":"<p>To access the EC2 instance, there are two primary methods:</p> <ol> <li>Amazon Cloud Console: Utilize the AWS Management Console to interact with the EC2 instance.</li> <li>Integrated Development Environment (IDE): Use your preferred IDE with SSH access. It is crucial to have the corresponding .pem file on your machine to establish a secure connection.</li> </ol> <p>Note - to access the EC2 instance you will need the pem file associated with the ec2 instance, you will be able to find it in the AWS secret manager.</p>"},{"location":"aws-deployment/#elastic-ip-address","title":"Elastic IP Address","text":"<p>The EC2 instance is assigned an elastic IP address. This ensures that the instance retains a static IP address, even if it is stopped or restarted, providing consistency for accessing and managing the instance.</p>"},{"location":"aws-deployment/#database-integration","title":"Database Integration","text":"<p>The EC2 instance is linked to an RDS database (uk-backstage-db) which handles all the application's database operations. This integration is facilitated through a security group (rds-ec2-1) that connects the two services securely.</p> <p>Note: To ensure seamless operation of the RDS database with Backstage, verify that the database environment variables are accurately set and exported. These variables should be correctly referenced in the app-config.yaml file to allow Backstage to successfully locate and interact with the database. <pre><code>#example\n      host: ${BSTAGE_DATABASE_ENDPOINT}\n      port: 5432\n      user: postgres\n      password: ${BSTAGE_DATABASE_PASSWORD}\n</code></pre></p>"},{"location":"aws-deployment/#future-developments-of-the-aws-infrastructure","title":"Future developments of the AWS infrastructure","text":"<p>The following shows a proposed architecture for delivering containerised services using AWS ECS Fargate.</p> <p></p>"},{"location":"aws-deployment/#architecture-overview_1","title":"Architecture Overview","text":""},{"location":"aws-deployment/#public-and-private-subnets","title":"Public and Private Subnets","text":"<p>The AWS network is segregated into a Public and Private subnet.  Separating resources that are publicly accessible from those resources that do not require access publicly is a more secure and cost effective pattern:</p> <p>Reducing the attack service for those resources that do not need a public IP address limiting potential security risks.  Reducing data transfer costs since the private subnet can communicate and exchange data with any other resources in the same AWS VPC for free, whereas exchanges between different VPCs are usually charged.</p>"},{"location":"aws-deployment/#ssl-custom-domain-ssl-certificate-and-alb-rules","title":"SSL Custom Domain, SSL Certificate and ALB Rules","text":"<p>AWS Certificate Manager, Route 53 DNS and rules at the Application Load Balancer are used to ensure access to the application is only allowed over a https/TLS connection which is encrypted, therefore traffic between the browser and the web cannot be read by an attacker.</p> <p>AWS Certificate Manager authenticates the endpoint so that the end user is sure that they are communicating with the legitimate website and not a site impersonating the endpoint.</p> <p>Route 53 maps incoming web requests to the application load balancer using a DNS Alias record.</p> <p>An appropriate rule at the Application Load Balancer redirects any traffic on port 80 (http) to port 443 (https)</p>"},{"location":"aws-deployment/#web-application-firewall","title":"Web Application Firewall","text":"<p>This is a series of rules and access control lists that are applied to incoming traffic so that any requests that do not meet set requirements can be rejected. </p> <p>All traffic is blocked by default and only traffic matching a defined rule is allowed through to the Application Load Balancer.</p> <p>IP sets can be created so that services can be restricted to only on-net or on-ons-vpn devices or specific ip addresses.</p> <p>Rule groups allow a combination of rules to be applied, the rules can pattern match on elements of the request (e.g the host header) and apply an ip set as a filter. This allows you to define that access to newservice.sdp-sandbox.aws.onsdigital.uk is only reachable from an on-net/ons-vpn device.</p>"},{"location":"aws-deployment/#application-load-balancer","title":"Application Load Balancer","text":"<p>An Application Load Balancer is staged in the public subnet and fronts the backend services.  This is the central point for serving any traffic from the internet. The load balancer allows scaling of backend services, providing the ability to distribute traffic to multiple end points as demand grows. </p> <p>A security group is applied at the load balancer to ensure nonsecure traffic is redirected to port 443 to ensure only https traffic is allowed.</p> <p>As it is the central point for incoming traffic it is also the place where rules can be added to ensure that Cognito authentication is required based on the endpoint the request is destined for.</p> <p>This allows you to define that if the host header includes newservice.sdp-sandbox.aws.onsdigital.uk then the request must be authenticated with Cognito before being forwarded to the backend service.</p>"},{"location":"aws-deployment/#cognito","title":"Cognito","text":"<p>Authentication to services is provided by AWS Cognito.  This service allows authentication to be implemented using standard practices with proven code all managed by the AWS identity provider which supports sign-up, password complexity, password reset and and forgotten password functionality out of the box.</p> <p>User groups can be configured to allow sign up to an application via email, users in these user groups are then authenticated at the Application Load Balancer when requests are made to the protected service.</p> <p>Notes: </p> <ol> <li>Cognito can be integrated with Azure Active Directory to allow SSO authentication (access) to applications.  This pattern has been proven by SPP User Management but is ToDo for the above architecture.</li> <li>Cognito and Azure Active Directory can also be used to provide a layer of authorisation to allow different users different levels of access in a given application (e.g role based access control).  This pattern has also been proven by SPP User Management but is ToDo for the above architecture.</li> </ol>"},{"location":"aws-deployment/#target-group","title":"Target Group","text":"<p>A target group is a logical mapping that allows the Application Load Balancer to map received traffic to an end service.  Initially there is a single target group that is applied in a forwarding rule at the load balancer and the same target group is associated with an ECS service.</p> <p>This logical mapping between ALB forwarding rules and Services will allow multiple services to be configured on the same load balancer and the traffic distributed accordingly based on the provisioned target groups.</p>"},{"location":"aws-deployment/#nat-gateway","title":"NAT Gateway","text":"<p>A NAT Gateway, hosted in the public subnet, allows any services that are in the private subnet to route traffic to the public internet without exposing the ip address of the private resource ensuring that external actors cannot obtain information that could compromise the solution.</p>"},{"location":"aws-deployment/#elastic-container-service","title":"Elastic Container Service","text":"<p>This AWS service comprises a number of resources that together allow containerised applications to be spun up and activated without the need to manage any underlying resources.</p> <p>A security group is defined at the service level which restricts traffic to only come from the application load balancer and expect traffic on specific ports (e.g to map traffic from the load balancer received on port 80 to the internal container port, e.g 8501 for default Streamlit port).</p> <p>Based on a task definition profile AWS will load a specified container image, monitor the application and ensure that a minimum number of tasks are always running, this enables auto healing when a task develops a fault as AWS will immediately detect and spin up a new instance.</p> <p>The ability to grow and shrink tasks based on demand will enable the SDP to scale to meet traffic and should reduce costs as instances are allocated only as and when they are needed.</p> <p>Deployment requirements can be specified that ensure a minimum of one instance of the service is available when a new deployment is being made, this allows a rolling update with zero down time to users. The deployment will spin up the new container image in a new task, wait for it to become active and then dry up and remove the task running the previous container image.</p> <p>If multiple different services need to be supported, this can be achieved simply by defining a new service, task definition and target group appropriate to the new service.</p>"},{"location":"aws-deployment/#elastic-container-registry","title":"Elastic Container Registry","text":"<p>The Elastic Container Registry (ECR) service acts like Docker Hub, providing a central store for containerised application images. The developer makes changes to application code locally, builds a docker image and then uploads this image to ECR.  A centralised store for container images allows for consistent deployments as all image versions are stored and deployed from a single location and can provide extra security by scanning images for known vulnerabilities.</p> <p>Amazon ECR also integrates easily with other AWS services simplifying deployment.</p>"},{"location":"core_features/","title":"Core Features","text":""},{"location":"core_features/#software-catalog","title":"Software Catalog","text":"<p>The catalog serves as a comprehensive repository for tracking various components within Backstage, which is one of its core functionality. Examples of catalog items include GitHub repositories, documentation sites, cloud resources, teams, and team members. Backstage exhibits flexibility in accommodating a wide array of components relevant to software development projects.</p> <p>By storing this information within Backstage, it provides a clear view of any information that might be relevant to a project. This includes how components of projects fit together, who is responsible for what, open pull requests, cloud resource health, etc. Most of the rest of Backstage revolves around this information and making clever use of it.</p> <p>Open-source plugins from the community can provide additional functionality to the Catalog by integrating with external services and pulling in relevant data from them. See SDP: Integrations for some examples. </p> <p></p> <p>Catalogue entities are defined using YAML files. Typically these will reside in thier project repositories but they can also be entered directly into the database without a YAML file having to actually exist somewhere external to Backstage (this is how certain integrations automatically \"discover\" users into the catalogue.</p>"},{"location":"core_features/#software-templates","title":"Software Templates","text":"<p>Software templates are essentially a set of instructions which tell Backstage to execute a series of actions with certain user inputs. This is a highly flexible system which can be adapted into a large range of use-cases. </p> <p>For example:</p> <ul> <li> <p>Creating a fresh repository for a Python project, with best-practice configurations already set, project structure according to standards, tests and CI already running and documentation skeleton included.</p> </li> <li> <p>Provisioning an S3 bucket in AWS and automatically configuring it for web hosting, then uploading a template for a website to it.</p> </li> <li> <p>Converting Confluence documentation into Markdown, then uploading it to a repository to be viewable within Backstage.</p> </li> </ul> <p>Templates are YAML files which consist of three main parts:</p> <ul> <li> <p>Parameters - determining the user inputs to the template. Backstage automatically produces the user input interface from these parameters.</p> </li> <li> <p>Steps - determining the actions the template should take based on the parameters. A set of default actions is included within Backstage - additional actions can be installed using plugins, or written yourself. </p> <p>See the page on writing custom template actions here.</p> <p>A typical flow could involve using fetch:template to move (and replace variables for) files into the workspace, then using a publish action to put them somewhere.</p> <p>Note - that templates are commonly stored alongside a \"content\" or \"skeleton\" folder, from which the files intended for templating are fetched. Alternatively, templates can also be sourced directly from a template repository using its URL. The execution of steps within templates can be made conditional based on the values of variables sourced from the parameters stage.</p> </li> <li> <p>Output - determining what the user should see once the actions have completed.</p> </li> </ul> <p>Templates, like most things in Backstage, are entities. This means that they are loaded into the catalog like anything else. However, as long as you don't need dynamic addition/removal of templates, they can reasonably be included using static configuration (manually pointed to in Backstage's app-config.yaml). Note that this is infeasible for most entities.</p> <p>Backstage provides some example templates, which can be found in the official repository. However, it appears that community-published templates are scarce, contrary to what one might expect. </p> <p>This scarcity suggests that the primary approach to sourcing templates is for them to be created on an as-needed basis by the internal team managing the platform. This approach is likely due to the fact that different organizations have significantly varied requirements and integrations, necessitating customized solutions.</p>"},{"location":"core_features/#automatic-repo-configuration","title":"Automatic Repo Configuration","text":"<p>Since we want newly created repos to follow best practices, we want them to have configuration options like branch protection already enabled. Here's how a few of them ended up:</p> <ul> <li> <p>Branch protection: implemented using Scaffolder actions, only available on public repos (or repos owned by accounts with GitHub Pro).</p> </li> <li> <p>Security scanning: GitHub security scanning is only available for public repos, or repos on GitHub Enterprise. You can also use an alternative method using Bandit which automatically checks for security issues via GitHub Actions.</p> </li> <li> <p>Secret scanning: GitHub secret scanning is only available for public repos, or repos on GitHub Enterprise.</p> </li> <li> <p>Dependabot: The Dependabot section of the GitHub API is still in public beta; there's no endpoint for enabling Dependabot that I could find (although there are a few for interacting with it). Might be worth failing the CI checks until Dependabot is enabled?</p> </li> </ul>"},{"location":"core_features/#techdocs","title":"TechDocs","text":"<p>TechDocs is Backstage's integrated documentation-as-code solution, built on top of MkDocs.</p> <p>The primary advantage of this approach is the seamless integration between documentation and software, making both easily accessible and maintainable. Another significant benefit is the simplicity and speed of writing documentation in Markdown, which renders in a highly presentable format.</p> <p></p> <p>To utilize TechDocs, documentation must be written in Markdown. The backstage.io/techdocs-ref configuration must be set in app-config.yaml to point to a directory containing the documentation folder, which is named \"docs\" by default. Additionally, a mkdocs.yaml file must be present in the same directory to define the structure of the documentation, as detailed in the MkDocs documentation.</p> <p>For optimal integration, it is recommended to locate the documentation alongside the code. This enhances visibility within Backstage and encourages developers to keep the documentation up to date.</p> <p>In cases where a single documentation site needs to cover multiple repositories or projects (e.g., both sml-python-small and statistical-methods-library), a standalone repository may be preferable. Projects in Backstage can link to the external documentation by setting backstage.io/techdocs-ref in their respective app-config.yaml files to url: instead of the default 'dir:..'. <p>There are a few nuances to note:</p> <ol> <li>The root page must be named index.md.</li> <li>The integrated search bar only appears when viewing the created documentation entity, not when viewing the \"docs\" tab in the original entity.</li> </ol> <p>This structured approach ensures that documentation remains closely linked with the codebase, promoting better maintenance and accessibility.</p>"},{"location":"core_features/#api-documentation","title":"API documentation","text":"<p>Backstage offers a plugin that provides a robust \"API explorer\" interface, enabling users to list endpoints, view descriptions, and even generate requests directly from within Backstage. To utilize this feature, an entity must be defined as an API in its catalog-info.yaml file, with the API definition provided under the spec.definition key. Backstage supports three formats for these definitions: OpenAPI, AsyncAPI, and GraphQL.</p> <p></p>"},{"location":"core_features/#tech-radar","title":"Tech Radar","text":"<p>Backstage's integrated Tech Radar allows organisation managers to outline best practices when it comes to technology adoption. By nature, this should be manually curated (assigning HOLD/ASSESS/TRIAL/ADOPT) but some aspects may be dynamically populated using information from a variety of sources. The SDP uses project data to link technologies to the projects which use them.</p> <p></p> <p>To populate the radar, data is served from a given client implementing the TechRadarApi interface - this means that you can provide your own source of data and that updating the radar does not require a change to the source of the Backstage frontend. Although complex implementations are possible, it is just as reasonable to read the radar information straight from a JSON file on disk.</p> <p>For further information, regarding how the tech radar is customised or how the project data is inserted into the SDP tech radar click here.</p>"},{"location":"core_features/#theming-and-ui","title":"Theming and UI","text":"<p>Backstage is a React app, which means that the frontend is highly customisable. There has been a small colour change using some of the ONS colours and the demo custom theme provided by Backstage. Custom themes are made by passing configuration options to a theme-creator method, where you can change any of the common colours, fonts and shapes used across the app.</p> <p>More advanced customisation is possible through directly editing the React source under packages/app. This provides full control over the frontend of Backstage; for example, you could add or remove elements from the sidebar, or construct a landing page for easier navigation.</p>"},{"location":"custom_plugins/","title":"Custom Plugins","text":"<p>This part of the documentation will cover creation of a basic backstage plugin and plugins that have been developed and are currently used by the SDP.</p>"},{"location":"custom_plugins/#create-a-plugin","title":"Create a Plugin","text":"<p>To create a new frontend plugin, make sure you've run <code>yarn install</code> and installed dependencies, then run the following on your command line (a shortcut to invoking the backstage-cli new --select plugin) from the root of your project.</p> <p><code>yarn new --select plugin</code></p> <p></p> <p>This will create a new basic front end Backstage Plugin template based on the ID that was provided. It will be built and added to the Backstage App automatically. From here you are able to develop the plugin in any way you want.</p>"},{"location":"custom_plugins/#other-plugin-library-package-types","title":"Other Plugin Library Package Types","text":"<p>There are other plugin library package types that you can chose from. To be able to select the type when you create a new plugin just run: <code>yarn new</code>. You'll then be asked what type of plugin you wish to create like this:</p> <p></p> <p>For a more extenisve documentation on plugin development in backstage click this link.</p>"},{"location":"custom_plugins/#plugins-developed-for-the-sdp","title":"Plugins developed for the SDP","text":""},{"location":"custom_plugins/#aws-s3-bucket-plugin","title":"AWS S3 Bucket Plugin","text":"<p>This plugin was developed to display associated S3 buckets with the catalog component.</p> <p></p> <p>The plugin was created using the yarn create command to template basic plugin environments for both the front-end and the backend.</p> <p>For the initial setup to connect the front-end and backend, the development followed this tutorial.</p> <p>The primary development of the plugin was conducted in the routes.ts file in the backend, utilizing the AWS SDK to retrieve the necessary information from the associated AWS account.</p> <p>The code in route.ts sets up an Express router to interact with AWS S3, enabling the retrieval of various bucket-related data. </p> <p>Here's a concise summary:</p>"},{"location":"custom_plugins/#imports-and-interface-definition","title":"Imports and Interface Definition:","text":"<p>Imports express, winston (for logging), @backstage/config (for configuration), and aws-sdk. Defines RouterOptions interface including config and logger.</p>"},{"location":"custom_plugins/#router-creation","title":"Router Creation:","text":"<p>createRouter function initializes AWS SDK with credentials and region from the configuration. Creates an S3 client instance. Sets up an Express router with a /health endpoint to fetch and return bucket data.</p>"},{"location":"custom_plugins/#aws-sdk-configuration","title":"AWS SDK Configuration:","text":"<p>Configures AWS SDK using credentials (accessKeyId, secretAccessKey) and region specified in the configuration file.</p>"},{"location":"custom_plugins/#health-check-endpoint","title":"Health Check Endpoint:","text":"<p>Defines a /health endpoint that fetches and responds with bucket data. Logs errors and returns a server error response if data fetching fails.</p>"},{"location":"custom_plugins/#bucket-data-functions","title":"Bucket Data Functions:","text":"<p>Asynchronous functions fetch specific S3 bucket data:</p> <ul> <li>getBucketRegions: Retrieves bucket regions.</li> <li>getBucketVersioningStatus: Checks versioning status.</li> <li>getBucketObjects: Lists objects.</li> <li>getBucketTags: Fetches tags.</li> <li>isBucketPublic: Determines public accessibility.</li> <li>getBucketSize: Calculates total object size.</li> <li>getCreationDate: Gets creation dates.</li> <li>getBucketEncryptionStatus: Checks encryption status.</li> <li>getBucketEncryption: Retrieves encryption types.</li> </ul> <p>Fetching All Bucket Data:</p> <ul> <li>fetchBucketData function combines results from Bucket Data functions to provide comprehensive bucket data.</li> </ul>"},{"location":"custom_plugins/#associating-aws-account","title":"Associating AWS Account","text":"<p>To associate an AWS account with the portal and the S3 viewer plugin, a new integration was added to app-config.yaml as shown below:</p> <pre><code>integrations:\n  s3viewer:\n    accessKeyId: ${AWS_ACCESS_KEY_ID}\n    secretAccessKey: ${AWS_SECRET_ACCESS_KEY}\n    sessionToken: ${AWS_SESSION_TOKEN}\n</code></pre> <p>The IDs and secrets are subsequently pulled and applied to the AWS configuration to ensure that the plugin obtains the required account information to associate the AWS account.</p> <pre><code>  AWS.config.update({\n    region: 'eu-west-2',\n    apiVersion: 'latest',\n    accessKeyId: config.getString('integrations.s3viewer.accessKeyId'),\n    secretAccessKey: config.getString('integrations.s3viewer.secretAccessKey'),\n  });\n</code></pre>"},{"location":"custom_plugins/#frontend-ui-development","title":"Frontend UI development","text":"<p>Once the backend development was finalized, the focus shifted to the frontend development. The primary objectives were to ensure that the frontend plugin could successfully make API calls to the backend, retrieve all necessary data, and generate a user interface to display this data effectively.</p> <p>The frontend implementation involved the following key tasks:</p> <ul> <li> <p>API Integration: Establishing a robust mechanism for the frontend plugin to communicate with the backend API, ensuring reliable data retrieval.</p> </li> <li> <p>Data Handling: Efficiently processing and managing the data received from the backend to prepare it for presentation.</p> </li> <li> <p>UI Development: Designing and developing a user-friendly interface to display the data. This involved using backstage's Material-UI components to create a custom component called 'Tab' which aligned with the overall design principles of the application.</p> </li> </ul>"},{"location":"custom_plugins/#s3-association-with-catalog-component","title":"S3 association with catalog component","text":"<p>The S3 reasurces can be associated with a component by using the resource names in the component's catalog-info.yaml file located in its repository and inputing them under the cloud/bucket annotation, like so: </p> <pre><code># example\napiVersion: backstage.io/v1alpha1\nkind: Component\nmetadata:\n  name: Software-Developer-Portal\n  description: Software Developer Portal\n  annotations:\n    jira/project-key: SPP\n    github.com/project-slug: ONS-Innovation/Software-Developer-Portal\n  tags:\n    - app\n    - spp\n///\ncloud:\n    provider: \"AWS\"\n    buckets: demowebsite7861, cf-templates-p13wahha5ywe-eu-west-2, dstdemowebsite129922\n///\nspec:\n  type: app\n  lifecycle: production\n  owner: user:default/wojciechp-ons\n</code></pre> <p>Note: the provider is set to 'AWS' for the time being as this is a PoC plugin and for further development it could include other providers such as GCP and Azure.</p>"},{"location":"custom_plugins/#github-releases-plugin","title":"GitHub Releases Plugin","text":"<p>This plugin was developed to display catalog component's github repository releases. </p> <p></p> <p>The plugin was created using the yarn create command to template basic plugin environments for both the front-end and the backend.</p> <p>For the initial setup to connect the front-end and backend, the development followed this tutorial.</p> <p>The primary development of the plugin was conducted in the routes.ts file in the backend, utilizing the Github's API to retrieve the necessary information from the associated repositories.</p> <p>The backend plugin sets up an Express router to interact with GitHub's API to fetch release data from repositories. </p> <p>Here's a concise summary for it:</p>"},{"location":"custom_plugins/#imports-and-router-setup","title":"Imports and Router Setup:","text":"<p>Imports express, @backstage/config, @octokit/auth-app, and @octokit/request. Creates an Express router instance.</p>"},{"location":"custom_plugins/#interface-definition","title":"Interface Definition:","text":"<p>Defines RouterOptions interface containing a simplified logger and a configuration object.</p>"},{"location":"custom_plugins/#release-interface","title":"Release Interface:","text":"<p>Defines Release interface to structure release data.</p>"},{"location":"custom_plugins/#router-creation-function","title":"Router Creation Function:","text":"<p>createRouter function sets up a /health endpoint.</p> <p>The endpoint requires repository and owner query parameters.</p> <p>Logs the request and validates parameters.</p> <p>Calls fetchReleases to get release data and responds with the data or an error message.</p>"},{"location":"custom_plugins/#github-app-authentication","title":"GitHub App Authentication:","text":"<p>Configures GitHub App authentication using createAppAuth with credentials from environment variables.</p>"},{"location":"custom_plugins/#access-token-function","title":"Access Token Function:","text":"<p>getInstallationAccessToken function retrieves an installation access token using the GitHub App credentials.</p> <p>Calls getInstallationId to fetch the installation ID from environment variables.</p>"},{"location":"custom_plugins/#fetch-releases-function","title":"Fetch Releases Function:","text":"<p>fetchReleases function fetches release data from a specified GitHub repository.</p> <p>Uses the access token for authenticated requests.</p> <p>Fetches the latest tags and commit messages for each release.</p> <p>Logs relevant information and errors.</p>"},{"location":"custom_plugins/#environment-variables","title":"Environment Variables:","text":"<p>Requires the following environment variables:</p> <pre><code>GITHUB_APP_ID\n\nGITHUB_APP_PRIVATE_KEY\n\nGITHUB_APP_CLIENT_ID\n\nGITHUB_APP_CLIENT_SECRET\n\nGITHUB_APP_INSTALLATION_ID\n</code></pre> <p>These environment variables are associated with the GitHub App credentials.</p>"},{"location":"custom_plugins/#repository-parameters","title":"Repository Parameters:","text":"<p>The repository parameters are retrieved using a hook in the front end plugin 'useReleasesObjects.ts' </p> <ul> <li>repositoryName</li> </ul> <p><code>const repositoryName = entity?.metadata?.name;</code> </p> <p>fetches the repositoryName parameter from the entity's catalog-info.yaml located in its repository.</p> <ul> <li>ownerName</li> </ul> <p><code>const ownerName = \"ONSDigital\"</code></p> <p>the ownerName parameter is currently hard-coded as 'ONSDigital' due to the SDP not being deployed in the ONSDigital org as of yet and it allows to showcase the potenital of the PoC, once the app is deployed in ONSDigital there is an available piece of code to replace the current workaround:</p> <pre><code>// Use the following code to extract the owner name from the project slug annotation\n  // const projectSlug = entity?.metadata?.annotations?.['github.com/project-slug'];\n  // const ownerName = projectSlug ? projectSlug.split('/')[0] : undefined;\n</code></pre>"},{"location":"custom_plugins/#frontend-ui-development_1","title":"Frontend UI development","text":"<p>Once the backend development was finalized, the focus shifted to the frontend development. The primary objectives were to ensure that the frontend plugin could successfully make API calls to the backend, retrieve all necessary data, and generate a user interface to display this data effectively.</p> <p>The frontend implementation involved the following key tasks:</p> <ul> <li> <p>API Integration: Establishing a robust mechanism for the frontend plugin to communicate with the backend API, ensuring reliable data retrieval.</p> </li> <li> <p>Data Handling: Efficiently processing and managing the data received from the backend to prepare it for presentation.</p> </li> <li> <p>UI Development: Designing and developing a user-friendly interface to display the data. This involved using backstage's Material-UI components to create a custom component called 'card' which aligned with the overall design principles of the application.</p> </li> </ul>"},{"location":"integrations/","title":"Integrations and Plugins","text":"<p>This page documents some of the plugins and integrations that have been added to the SDP, alongside some discussion of their pros and cons.</p>"},{"location":"integrations/#github","title":"GitHub","text":"<p>There are many possibilities with the GitHub integration. One notable feature is its ability to automatically import user, group, and repository information into the catalog. This eliminates the need to manually locate catalog-info.yaml files for all components, ensuring immediate visibility of any new entities in the portal.</p>"},{"location":"integrations/#authentication-and-permissions","title":"Authentication and permissions","text":"<p>Currently, GitHub handles the authentication for the SDP. This allows for ownership information to be readily available, as well as handling permissions for access to repositories.</p> <p>The sign-in system in Backstage is not intended to limit access, only to inform the system of the identity of the user (and provide access tokens for certain integrations). Access limitation is handled by the permission framework as mentioned below.</p> <p>By default, Backstage endpoints are not protected, and all actions are available to anyone. However, the permission framework allows integrators to achieve this through the use of granular permissioning for those resources and actions.</p> <p>The SDP uses backstage's permission framework to authnticate access to specific parts of the portal, such as the tech radar or the whole application access dependand on the role based authentication attached to specific groups within the GitHub Org.</p> <p>Current roles are as follows:</p> <ul> <li> <p>Admin </p> <ul> <li>Full application access </li> <li>Entity creation </li> <li>Entity deletion</li> </ul> </li> <li> <p>Dev-Team</p> <ul> <li>Full application access </li> <li>Entity creation</li> </ul> </li> <li> <p>spp-sml </p> <ul> <li>Tech radar access</li> </ul> </li> </ul> <p>These roles can be changed or renamed dependant on the configuration of the SDP.</p> <p>for more information go to Authentication and permissions</p>"},{"location":"integrations/#jira","title":"Jira","text":"<p>The Jira integration works by specifying a proxy in app-config.yaml in the Backstage project root. This requires a \"target\", which is the domain that is hosting Jira - for testing purposes, I've set up a dummy organisation at https://akira.atlassian.net/ but this would obviously be replaced by https://jira.ons.gov.uk/ in production. The application also requires an authorisation header using a token generated by the organisation; </p> <p>Obtain you personal token from Jira.</p> <p>Create a base64-encoded string by converting a string in format</p> <p><code>&lt;your-atlassian-account-mail&gt;:&lt;your-jira-token&gt;</code></p> <p>for example:</p> <p><code>jira-mail@example.com:hTBgqVcrcxRYpT5TCzTA9C0F</code></p> <p>converts to base64</p> <p><code>amlyYS1tYWlsQGV4YW1wbGUuY29tOmhUQmdxVmNyY3hSWXBUNVRDelRBOUMwRg==</code></p> <p>Save it as the environmental variable JIRA_TOKEN with Basic prefix, for example:</p> <p><code>JIRA_TOKEN='Basic amlyYS1tYWlsQGV4YW1wbGUuY29tOmhUQmdxVmNyY3hSWXBUNVRDelRBOUMwRg=='</code></p> <p>Alternatively, if you are running backstage locally, you can provide the variable by the command</p> <p><code>env JIRA_TOKEN='Basic amlyYS1tYWlsQGV4YW1wbGUuY29tOmhUQmdxVmNyY3hSWXBUNVRDelRBOUMwRg==' yarn</code></p> <p>Once set up, applying the integration to software components in the catalog is as simple as marking the catalog info file with a jira/project-key annotation. This annotation should map to the key that relates to the project that the component is part of - for example, all of the SML repos would be marked with SPP .</p>"},{"location":"integrations/#github-insights","title":"GitHub Insights","text":"<p>GitHub Insights plugin provides repository insights about contributors, languages, readme, and enviroments - this is the same information that you can see found directly on GitHub but it allows the user to view insights wigets for corresponding componetnts in the catalog  </p>"},{"location":"integrations/#aws","title":"AWS","text":"<p>There are two main providers of AWS-Backstage plugins: AWS Apps and Roadie. These are based on the AWS SDK, which is both straightforward to install and easy to make use of. This means that a lot of the AWS functionality can reasonably be done from scratch - for a lot of our use-cases, I think this approach is best.</p> <p>The existing plugins are discussed below for completeness.</p>"},{"location":"integrations/#awslabs","title":"AWSLabs","text":"<p>AWS themselves provide three such plugins: aws-apps-backend, aws-apps and scaffolder-backend-module-aws-apps (which are available here). Most notably, these allow (among other things):</p> <ul> <li>Discovery of AWS resources as Backstage entities (such that they're visible in the Software Catalog, with a custom frontend for their pages)</li> <li>UI cards to monitor AWS resources from within Backstage</li> <li>Scaffolder actions to provision AWS resources using templates</li> </ul> <p>However, the project containing these plugins seems intended to be used as a standalone AWS management platform as opposed to integrated into an existing Backstage app.</p>"},{"location":"integrations/#roadiehq","title":"RoadieHQ","text":"<p>The alternative is the Roadie-developed set of Backstage AWS plugins which appears to be more tailored towards being incorporated into an existing Backstage app. However, these have significant limitations:</p> <p>The range of resources that it can track is very limited - it only recognises S3 buckets, ECRs and Lambda actions.</p> <p>The frontend for these resources does not seem particularly mature. Aside from only providing a limited number of components, it's not present on yarn or npm, which means that you have to manually install it from source.</p> <p>These are useful actions, but they're very limited in scope.</p>"},{"location":"integrations/#chatgpt-and-ai-queries","title":"ChatGPT and AI queries","text":"<p>The plugin developed by Enfuse offers a simple user interface for interacting with ChatGPT through OpenAI's chat completion API. Although limited on its own, functioning essentially as a basic version of the OpenAI user interface, the framework provided allowed for the creation of a chat window that enables users to query ChatGPT using information stored within Backstage's database. This provides a natural language interface for exploring Backstage.</p> <p>To achieve this, context retrieved from Backstage's entity catalogue database (specifically, the YAML files describing entity metadata) was injected into the system prompt, along with a directive for ChatGPT to use that context in its responses. Consequently, when users ask questions, ChatGPT can utilize the metadata to generate informed answers about Backstage's knowledge.</p>"},{"location":"integrations/#token-limitations","title":"Token Limitations","text":"<p>However, the model used, ChatGPT-3.5-Turbo, has a combined token limit of 4096 tokens for both system and user prompts. This limit is insufficient to send the entire database content, even when restricted to catalog-info.yaml metadata files, necessitating a method to select the data sent to ChatGPT.</p> <p>OpenAI's \"embeddings\" API, which vectorizes text, provides a solution. By vectorizing the database items and the user query, and then comparing them using cosine similarity, a ranking from \"most relevant\" to \"least relevant\" is produced. The top N most relevant database items can then be selected as context.</p> <p>Despite often yielding good results, this approach has fundamental flaws. Since ChatGPT cannot access the entire database at once, it cannot accurately answer large aggregate queries (such as \"how many entities are tracked in the database\" or \"list all entities not using Python\") unless all relevant information is contained within the metadata of a small number of entities. There is no real workaround for this issue, but it might not be problematic in a production environment. For instance, the Office for National Statistics (ONS) would likely avoid sending potentially sensitive data to OpenAI, opting instead to host their own language model locally. This would eliminate the token limit issue, though other challenges such as performance and relevance with extremely large contexts might arise.</p>"},{"location":"tech_radar_customisation/","title":"Tech Radar Customisation","text":"<p>The Tech Radar is a frontend plugin which works out the box as part of basic Backstage set up. You might notice that the only reference to the Tech Radar in code is when it's mentioned in as a TechRadarPage in packages/app/src/App.tsx. This is because all of its code is neatly packaged inside the plugin and not part of Backstage's source.</p> <p>You should be able to find the plugin's code in the node module folder - node_modules/@backstage/plugin-tech-radar - alongside the code for all the rest of the installed plugins. </p> <ul> <li>Note: Be careful, though - these files are handled by yarn and npm, so any changes you make won't survive a yarn install. If you do need to make changes to a plugin's code, you should copy its source to a folder and create a new plugin using these instructions.</li> </ul>"},{"location":"tech_radar_customisation/#custom-api","title":"Custom API","text":"<p>Although it's possible to change the Tech Radar as above, all we really need to do to make use of it, is to provide our own API. Essentially, there's a TechRadarApi interface that is required to implement and fill with data.</p> <p>You can create a new file somewhere nearby - (For the SDP we created a tech_radar folder next to components but it doesn't really matter where you put it) and start structruing it as shown below:</p> <pre><code>import {\n    TechRadarApi,\n    TechRadarLoaderResponse,\n    RadarEntry,\n    RadarEntryLink,\n} from '@backstage/plugin-tech-radar';\n\nexport class OnsRadar implements TechRadarApi {\n    async load(id: string | undefined): Promise&lt;TechRadarLoaderResponse&gt; {\n        // ...\n    }\n}\n</code></pre> <p>Inside the load function, we want to return the information that the Tech Radar should display. The structure of this is defined by the TechRadarLoaderResponse.</p> <p>While building the loader response, we can fill it with any data we like (For the SDP we are using the project information to showcase the tech usesage within the org). For now the data is hard-coded, but could implement dynamic updates in future iterations, but this would require further investigation.</p>"},{"location":"tech_radar_customisation/#actually-using-the-api","title":"Actually using the API","text":"<p>The next step is to tell Backstage about our API.</p> <p>In packages/app/src/apis.ts you can find an exported a list of AnyApiFactory objects under the name apis. To change the Tech Radar API from its default example state, we're going to overwrite the reference:</p> <pre><code>// ...\n\nimport { OnsRadar } from './tech_radar/onsRadarClient'; // or whatever you called it\nimport { techRadarApiRef } from '@backstage/plugin-tech-radar';\n\nexport const apis: AnyApiFactory[] = [ // note that this is a list, not a function! if you're getting a syntax error, it might be because you're not using commas to separate the items\n    // ... other apis...\n    createApiFactory(techRadarApiRef, new OnsRadar()),\n];\n</code></pre> <p>The Tech Radar should now display the data you have added. </p>"},{"location":"tech_radar_customisation/#software-developer-portal-tech-radar-converter","title":"Software Developer Portal Tech Radar Converter","text":"<p>A basic tool (tech_adoption_ui) was developed to convert CSV data set into JSON format. This tool was designed to process a CSV file that details the technologies adopted by each project within ONS and lets you categorise it into the seperate adoption sections 'HOLD/ASSESS/TRIAL/ADOPT'. </p> <p>The tool takes the data from the CSV file and formats it into a JSON structure, which is subsequently used by the SDP.</p> <p></p> <p>The tool is located here.</p>"},{"location":"tech_radar_customisation/#updating-data","title":"Updating Data","text":"<p>To update the Tech Radar with the most current data, place the newly generated JSON file in the following directory: /packages/app/public/tech_radar, naming it onsRadarSkeleton.json. Once the file is in this location, the updated data will automatically render on the page.</p> <p>Here are useful files:</p> <ul> <li>Full Clean JSON</li> <li>Full CSV</li> </ul>"},{"location":"tech_stack/","title":"Tech Stack","text":""},{"location":"tech_stack/#frontend","title":"Frontend","text":"<ul> <li> <p>React: A popular JavaScript library for building user interfaces, particularly single-page applications.</p> </li> <li> <p>TypeScript: A superset of JavaScript that adds static types, improving developer productivity and code quality.</p> </li> </ul>"},{"location":"tech_stack/#backend","title":"Backend","text":"<ul> <li> <p>Node.js: A JavaScript runtime built on Chrome's V8 JavaScript engine, used for building scalable and efficient server-side applications.</p> </li> <li> <p>Express: A minimal and flexible Node.js web application framework that provides a robust set of features for web and mobile applications.</p> </li> </ul>"},{"location":"tech_stack/#api-and-integration","title":"API and Integration","text":"<ul> <li>GraphQL: A query language for APIs that allows clients to request exactly the data they need, making it easier to integrate with various services and improve performance.</li> </ul>"},{"location":"tech_stack/#plugins-and-extensions","title":"Plugins and Extensions","text":"<ul> <li>Plugin System: Backstage supports a plugin-based architecture, allowing developers to extend its functionality by creating custom plugins. These plugins can integrate with various tools and services, such as CI/CD systems, cloud providers, monitoring tools, etc.</li> </ul>"},{"location":"tech_stack/#styling-and-ui-components","title":"Styling and UI Components","text":"<ul> <li>Material-UI: A popular React UI framework that implements Google's Material Design, providing a set of reusable and customizable UI components.</li> </ul>"},{"location":"tech_stack/#static-site-generation-and-documentation","title":"Static Site Generation and Documentation","text":"<ul> <li> <p>MkDocs: A static site generator that's geared towards project documentation. MkDocs is used in conjunction with Markdown to create and manage documentation.</p> </li> <li> <p>TechDocs: A documentation generator built into Backstage that integrates with MkDocs to provide an easy way to create and maintain technical documentation.</p> </li> </ul>"},{"location":"tech_stack/#authentication-and-authorization","title":"Authentication and Authorization","text":"<ul> <li> <p>OAuth: Backstage supports various authentication providers using OAuth to ensure secure access to the portal and its resources.</p> </li> <li> <p>Passport.js: An authentication middleware for Node.js that supports various authentication strategies, including OAuth.</p> </li> </ul>"},{"location":"tech_stack/#containerization-and-deployment","title":"Containerization and Deployment","text":"<ul> <li> <p>Docker: Used for containerizing the application, making it easier to deploy and manage in different environments.</p> </li> <li> <p>Kubernetes: Often used to orchestrate and manage containerized applications, providing scaling, deployment, and management capabilities.</p> </li> </ul>"},{"location":"tech_stack/#database","title":"Database","text":"<ul> <li>PostgreSQL: A powerful, open-source relational database system often used to store metadata and other persistent data for Backstage.</li> </ul>"},{"location":"tech_stack/#search","title":"Search","text":"<ul> <li>Elasticsearch: Used for powerful and scalable search capabilities within the Backstage platform.</li> </ul>"},{"location":"template_actions/","title":"Template actions","text":"<p>This page will serve as a useful intro to writing your own template actions as part of Backstage.</p>"},{"location":"template_actions/#introduction","title":"Introduction","text":"<p>The component of Backstage responsible for managing templates is known as the Scaffolder. Although it is technically a plugin, it comes pre-installed with Backstage. The Scaffolder is part of the backend, and the relevant code is located in packages/backend/src/plugins/scaffolder.ts.</p> <p>Within the scaffolder.ts file, there is a function called createPlugin. This function initializes the Scaffolder plugin, enabling the creation of custom actions. <pre><code>export default async function createPlugin(\n  env: PluginEnvironment,\n): Promise&lt;Router&gt; {\n // ...\n}\n</code></pre></p> <p>In the lower section of the function, there is a line declaring const builtInActions = createBuiltinActions(...). If you are using VSCode or a similar IDE, hovering over this function should display its return type, which is an array of TemplateAction.</p> <p>The result of this function is then spread into the actions array using the ... operator. To create custom actions, a similar approach is employed, adding them to the end of this array.</p>"},{"location":"template_actions/#creating-actions","title":"Creating Actions","text":"<p>It is important to note that Backstage has a dedicated page that lists all installed actions. This page can be accessed at the /create/actions endpoint, for example, http://localhost:3000/create/actions when running on localhost. This page will update as new actions are added.</p> <p></p> <p>To add new actions, create a function similar to the one shown below. While it can be placed in the scaffolder.ts file, it is recommended to organize it in a separate file for better maintainability. For instance, it can be placed in a folder named scaffolder and organized by type.</p> <p><pre><code>// you might need to add these if they aren't already present in the file you're working in\nimport { createTemplateAction } from '@backstage/plugin-scaffolder-node'\nimport { ScmIntegrations, DefaultGithubCredentialsProvider } from '@backstage/integration'\n\nexport const createXYZAction = () =&gt; {\n    return createTemplateAction({\n            // the action schema goes here - this is the object which describes the inputs and outputs of the action\n            // have a look at either the existing actions or the ones I've added for an idea of what this looks like\n        },\n        async handler(ctx) {\n            // this callback determines what the action actually does - you can put any code in here and it'll run when the action does\n            // the ctx (\"context\") object contains a bunch of useful stuff for this:\n\n            // - ctx.input contains the inputs you described in the schema object above. for example, ctx.input.repoUrl could have a GitHub URL that you use in the GitHub API\n            //   this works because the type of ctx.input is JsonObject, so its keys are determined at runtime - just make sure the names match up between the schema and here\n\n            // - ctx.output(\"key\", $value) is a *function* which lets you set the output of the action.\n            //   this isn't super commonly used unless you're making more complex actions, but it's good to know about\n\n            // - ctx.logger carries the logger object for the scaffolder. this gives you access to methods like ctx.logger.info() and ctx.logger.error(), which print messages to the log\n            //   the messages are visible both in the terminal window running backstage *and* inside the window that pops up while the template is running\n            //   these functions are incredibly useful for debugging!\n\n            // if you type \"ctx.\" into VSCode, it should show you all of the object members that you can make use of as autocomplete options\n        }\n    )\n}\n</code></pre> Note - It can be useful to to make a basic action to get familiar with the process.</p> <p>It is important to remember that template actions do not perform any tasks until they are incorporated into templates. Therefore, it is advisable to create an example template as well. </p> <p>However, ensure that the following step is completed first:</p> <ul> <li> <p>Making the Actions Available Now that an action has been created, it needs to be registered with Backstage. To do this, return to scaffolder.ts and import the function from the relevant file, for example, ./scaffolder/xyzActions or the appropriate name used.</p> <p>Next, add the newly created action to the list of actions:</p> <pre><code>const actions = [\n...builtInActions,\n// ...\ncreateXyzAction(),\n];\n</code></pre> <p>After completing this step, the new action should be visible at the /create/actions endpoint and ready to be used in templates.</p> </li> </ul>"},{"location":"useful-resources/","title":"Links to documentation","text":"<ul> <li>Typescript</li> <li>React</li> <li>Node.js</li> <li>Express.js</li> <li>Docker</li> <li>PostgreSQL</li> <li>Backstage</li> </ul>"},{"location":"useful-resources/#links-to-demo-videos","title":"Links to demo videos","text":"<ul> <li>Link to KEH confluence page click here to view useful demo videos explaing the SDP in more detail.</li> </ul>"}]}